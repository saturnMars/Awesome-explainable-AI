# Model Inspection

## Papers
[Unveiling LLMs: The Evolution of Latent Representations in a Dynamic Knowledge Graph](https://openreview.net/forum?id=dWYRjT501w), COLM 2024

[Transformer Interpretability Beyond Attention Visualization](https://arxiv.org/abs/2012.09838), CVPR 2021

[Quantifying Attention Flow in Transformers](https://arxiv.org/abs/2005.00928), ACL 2020

[Explaining Explanations: Axiomatic Feature Interactions for Deep Networks](https://arxiv.org/pdf/2002.04138.pdf), arxiv preprint 2020

[How does this interaction affect me? Interpretable attribution for feature interactions](https://arxiv.org/abs/2006.10965), NeurIPS 2020

[Automated Dependence Plots](http://www.auai.org/uai2020/proceedings/503_main_paper.pdf), UAI 2020

[FEATURE INTERACTION INTERPRETABILITY: A CASE FOR EXPLAINING AD-RECOMMENDATION SYSTEMS VIA NEURAL INTERACTION DETECTION](https://openreview.net/pdf?id=BkgnhTEtDS), ICLR 2020

ALE: [Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models](https://arxiv.org/abs/1612.08468), Journal of the Royal Statistical Society Series B (Statistical Methodology) 2020

[Causal Interpretations of Black-Box Models](https://www.tandfonline.com/doi/full/10.1080/07350015.2019.1624293), Journal of Business & Economic Statistics 2019

[Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models](https://dl.acm.org/doi/10.1145/2858036.2858529), CHI 2016

ICE: [Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation](https://arxiv.org/abs/1309.6392), Journal of Computational and Graphical Statistics  2013

PDP: [Greedy function approximation: A gradient boosting machine](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf), Annals of statistics 2001

## Github Repostories

Latent Explorer [https://github.com/Ipazia-AI/latent-explorer](https://github.com/Ipazia-AI/latent-explorer) ![](https://img.shields.io/github/stars/Ipazia-AI/latent-explorer.svg?style=social)

Alibi: [https://github.com/SeldonIO/alibi](https://github.com/SeldonIO/alibi) ![](https://img.shields.io/github/stars/SeldonIO/alibi.svg?style=social)

PDPbox: [https://github.com/SauceCat/PDPbox](https://github.com/SauceCat/PDPbox), Scikit-learn ![](https://img.shields.io/github/stars/SauceCat/PDPbox?style=social)

PyCEbox: [https://github.com/AustinRochford/PyCEbox](https://github.com/AustinRochford/PyCEbox) ![](https://img.shields.io/github/stars/AustinRochford/PyCEbox?style=social)
